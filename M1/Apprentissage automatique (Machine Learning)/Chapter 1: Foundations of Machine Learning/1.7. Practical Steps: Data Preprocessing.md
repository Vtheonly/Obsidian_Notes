# 1.7 Practical Steps: Data Preprocessing

## Context

Raw data is rarely in a clean, ready-to-use format for machine learning algorithms. **Data preprocessing** is the crucial step of cleaning, transforming, and structuring raw data to make it suitable for a model. This can have a massive impact on the final performance.

---

## Handling Categorical Data

Many algorithms require numerical inputs. Categorical data, which represents discrete labels (e.g., `['car', 'boat', 'plane']`), must be converted into a numerical format.

> The standard method for this is **One-Hot Encoding**. This technique creates a binary vector for each category. The vector is all zeros except for a single `1` at the index corresponding to the specific category.

>

> * `car` -> `[1, 0, 0]`

> * `boat` -> `[0, 1, 0]`

> * `plane` -> `[0, 0, 1]`

>

> This prevents the model from assuming an incorrect ordinal relationship between categories (e.g., that `plane` > `boat`).

---

## Dealing with Missing Values

Real-world datasets often contain missing values. These must be handled before training.

* **For Categorical Features**: A simple approach is to represent the missing value with an all-zero one-hot vector.

* **For Numerical Features**: A common strategy is to:

1. Replace the missing value with the mean or median of that feature across the entire dataset.

2. Add a new binary "indicator" feature that is `1` if the original value was missing and `0` otherwise. This allows the model to learn if the fact that a value is missing is itself informative.

---

## Feature Scaling (Normalization)

Many algorithms, especially those that rely on distances or gradients, perform better when input features are on a similar scale. If one feature ranges from 0 to 1 and another from 0 to 1,000,000, the latter can dominate the learning process.

> **Standardization** is the most common scaling technique. For each feature, it subtracts the mean and divides by the standard deviation.

>

> `x_scaled = (x - mean(x)) / std_dev(x)`

>

> This transforms the data to have a mean of 0 and a standard deviation of 1, putting all features on a common scale.

> [!Note] Importance of Preprocessing

> Data preprocessing is not just a preliminary chore; it is an integral part of the machine learning pipeline. Proper preprocessing can be the difference between a poorly performing model and a state-of-the-art one.

***