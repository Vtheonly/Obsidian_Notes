  

# 1.4 Core Challenges: Overfitting & Underfitting

## Context

A central challenge in machine learning is creating a model that not only performs well on the data it was trained on, but also generalizes to new, unseen data. This requires balancing model complexity, which leads to the concepts of underfitting and overfitting.

---

## Model Capacity and Complexity

**Model capacity** refers to the flexibility of a model to fit a wide variety of functions. A model with low capacity might be too simple to capture the underlying trend in the data, while a model with high capacity can model very complex relationships.

> The key is to match the model's capacity to the true complexity of the data-generating process. An imbalance leads to poor performance.

* **Underfitting**: This occurs when a model has **too little capacity**. It is too simple to capture the underlying structure of the data. An underfitting model performs poorly on both the training set and the test set because it fails to learn the relevant patterns.

* **Overfitting**: This occurs when a model has **too much capacity**. It learns the training data "by heart," including the random noise and fluctuations specific to that dataset. While it achieves extremely low error on the training set, it fails to generalize to the test set, resulting in high test error.

---

## Example: Polynomial Regression

Consider fitting a polynomial function to a set of data points. The degree of the polynomial, `M`, controls the model's capacity.

* **M = 0 or 1 (Underfitting)**: A constant or linear function is too rigid. It cannot capture the sinusoidal trend of the data, resulting in high error everywhere.

* **M = 3 (Good Fit)**: A cubic polynomial provides a good compromise. It captures the overall trend of the data without fitting every minor fluctuation (noise).

* **M = 9 (Overfitting)**: A 9th-degree polynomial has enough flexibility to pass exactly through every training point. However, it oscillates wildly between points and will perform very poorly on new data. It has learned the noise, not the signal.

---

## Key Points

* Model capacity

* Generalization error

* Training error

* Noise vs. signal

* Model complexity

* Bias-variance trade-off

> [!Note] The U-Shaped Error Curve

> As model capacity increases, the training error steadily decreases. However, the test error typically follows a U-shaped curve: it decreases at first (as the model learns the signal) and then starts to increase (as the model begins to learn the noise). The optimal model capacity lies at the bottom of this "U".

> [!Warning] Overfitting is Deceptive

> An overfit model looks perfect on training data, giving a false sense of high accuracy. Its poor generalization performance only becomes apparent when evaluated on a separate test set.

***